{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TimeSeries.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM9T46N3IhJhXP3LE2aSW4+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/johnnybigoode/practical-time-series/blob/main/TimeSeries.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EPGm9yP9uovQ"
      },
      "source": [
        "# Preface"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3mlXQ7mUuvQv"
      },
      "source": [
        "Starts with examples of things that form time series, like weather, stock markets and heartbeats.\n",
        "\n",
        "Reminds us of the future of IoT and the amount of sensors and gadgets available for high-quality time series data\n",
        "\n",
        "Expects a introductory statistics background\n",
        "\n",
        "There are at least two youtube 3h long scipy talks with the author on the subject\n",
        "\n",
        "https://www.youtube.com/watch?v=JNfxr4BQrLk\n",
        "\n",
        "https://www.youtube.com/watch?v=v5ijNXvlC5A&t=1s\n",
        "\n",
        "book errata\n",
        "https://www.oreilly.com/catalog/errata.csp?isbn=0636920187714\n",
        "\n",
        "github repo\n",
        "https://github.com/PracticalTimeSeriesAnalysis/BookRepo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lCmMTWgdvaJr"
      },
      "source": [
        "# Chapter 1 Time Series: Overview and Quick History"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OD7nLu2EvkCw"
      },
      "source": [
        "Time series: Data in choronological order\n",
        "\n",
        "Time series analysis: Diagnose the past and predict the future\n",
        "\n",
        "Medical field examples:\n",
        "\n",
        "electrocardiograms - records electrig signals passing thru the heart\n",
        "electroencephalogram - measures eletrical impulses in the brain\n",
        "\n",
        "examples of time series in weather:\n",
        "\n",
        "barometer - taking meassurements of the state of the atmosphere at regular invervals\n",
        "\n",
        "examples of time series in bussiness:\n",
        "\n",
        "forecasting demand, estimaging future raw materials prices, hedging on manufacturing costs\n",
        "\n",
        "examples of modern machine learning related to time-series:\n",
        "\n",
        "computer security, anomaly detection as a method for getting hackers and invader dynamic time warping, a way of checking similarity of time series\n",
        "recursive neural networks show usefulness for extracting patterns in corrupted data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O0agz-oYwRb-"
      },
      "source": [
        "# Chapter 2 All About The Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eBAlDhguwbs2"
      },
      "source": [
        "problems related to preprocessing time serries data\n",
        "\n",
        "-finding time series online\n",
        "Kaggle!\n",
        "UCI Machine Learning Repository\n",
        "UEA and UCR Time Series Classification Repository\n",
        "NOAA National Centers for Enviromental Information\n",
        "Bureau of Labor Statiscs\n",
        "Centers for Disease Control and Prevention\n",
        "Federal Reserve Bank of St Louis\n",
        "CompEngine\n",
        "Mcomop and M4comp2018 R Packages\n",
        "CRAN Repository\n",
        "\n",
        "*time series can be related to anything related that is sorted in time, such as the spectrum of a wine, with the wavelenghts evenly spaced on the x-axis\n",
        "\n",
        "*does this mean that using Fourier we can transform things in the frequency domain, to time domain and its somehow related?\n",
        "\n",
        "*data usually must be assembled from a collection of data\n",
        "\n",
        "Lookahead: time series information that was unknown when designing, traning or evalutating a model. This can and will screw things up. There's no test for it, something one must be vigilant and thoughtful.\n",
        "\n",
        "When counting information, remember to put back the data you removed, aquelas coisas relacionadas a calular incluindo os extremos\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JBgFrjjMx2o_",
        "outputId": "861918f8-430a-4a78-9a3d-90e4e0979b83"
      },
      "source": [
        "#table 2-1 https://raw.githubusercontent.com/johnnybigoode/BookRepo/master/Ch02/data/year_joined.csv\n",
        "#table 2-2 https://raw.githubusercontent.com/johnnybigoode/BookRepo/master/Ch02/data/emails.csv\n",
        "#table 2-3 https://raw.githubusercontent.com/johnnybigoode/BookRepo/master/Ch02/data/donations.csv\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "YearJoined = pd.read_csv(\n",
        "    \"https://raw.githubusercontent.com/johnnybigoode/BookRepo/master/Ch02/data/year_joined.csv\") \n",
        "print(YearJoined.head())\n",
        "\n",
        "Emails = pd.read_csv(\"https://raw.githubusercontent.com/johnnybigoode/BookRepo/master/Ch02/data/emails.csv\")\n",
        "print(Emails.head())\n",
        "\n",
        "Donations = pd.read_csv(\"https://raw.githubusercontent.com/johnnybigoode/BookRepo/master/Ch02/data/donations.csv\")\n",
        "print(Donations.head())"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   user userStats  yearJoined\n",
            "0     0    silver        2014\n",
            "1     1    silver        2015\n",
            "2     2    silver        2016\n",
            "3     3    bronze        2018\n",
            "4     4    silver        2018\n",
            "   emailsOpened  user                 week\n",
            "0           3.0   1.0  2015-06-29 00:00:00\n",
            "1           2.0   1.0  2015-07-13 00:00:00\n",
            "2           2.0   1.0  2015-07-20 00:00:00\n",
            "3           3.0   1.0  2015-07-27 00:00:00\n",
            "4           1.0   1.0  2015-08-03 00:00:00\n",
            "   amount            timestamp  user\n",
            "0    25.0  2017-11-12 11:13:44   0.0\n",
            "1    50.0  2015-08-25 19:01:45   0.0\n",
            "2    25.0  2015-03-26 12:03:47   0.0\n",
            "3    50.0  2016-07-06 12:24:55   0.0\n",
            "4    50.0  2016-05-11 18:13:04   1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "B3XlyoHSWIIF",
        "outputId": "8c91d76d-677c-4c5a-9c9a-efc928f9327e"
      },
      "source": [
        "#groupby example on dataframe\n",
        "YearJoined.groupby('userStats').count()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user</th>\n",
              "      <th>yearJoined</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>userStats</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>bronze</th>\n",
              "      <td>486</td>\n",
              "      <td>486</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gold</th>\n",
              "      <td>95</td>\n",
              "      <td>95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>inactive</th>\n",
              "      <td>96</td>\n",
              "      <td>96</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>silver</th>\n",
              "      <td>323</td>\n",
              "      <td>323</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           user  yearJoined\n",
              "userStats                  \n",
              "bronze      486         486\n",
              "gold         95          95\n",
              "inactive     96          96\n",
              "silver      323         323"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "id": "soRih2J-WpME",
        "outputId": "9383e293-116f-499d-b8f5-74b814319e3d"
      },
      "source": [
        "Emails[Emails.emailsOpened < 1]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>emailsOpened</th>\n",
              "      <th>user</th>\n",
              "      <th>week</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [emailsOpened, user, week]\n",
              "Index: []"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "s9_l9r_gW1IF",
        "outputId": "1e516f22-04a9-4208-ad86-dde43cfa8bfc"
      },
      "source": [
        "Emails[Emails.user == 998].head()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>emailsOpened</th>\n",
              "      <th>user</th>\n",
              "      <th>week</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>25464</th>\n",
              "      <td>1.0</td>\n",
              "      <td>998.0</td>\n",
              "      <td>2017-12-04 00:00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25465</th>\n",
              "      <td>3.0</td>\n",
              "      <td>998.0</td>\n",
              "      <td>2017-12-11 00:00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25466</th>\n",
              "      <td>3.0</td>\n",
              "      <td>998.0</td>\n",
              "      <td>2017-12-18 00:00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25467</th>\n",
              "      <td>3.0</td>\n",
              "      <td>998.0</td>\n",
              "      <td>2018-01-01 00:00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25468</th>\n",
              "      <td>3.0</td>\n",
              "      <td>998.0</td>\n",
              "      <td>2018-01-08 00:00:00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       emailsOpened   user                 week\n",
              "25464           1.0  998.0  2017-12-04 00:00:00\n",
              "25465           3.0  998.0  2017-12-11 00:00:00\n",
              "25466           3.0  998.0  2017-12-18 00:00:00\n",
              "25467           3.0  998.0  2018-01-01 00:00:00\n",
              "25468           3.0  998.0  2018-01-08 00:00:00"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mTRGST8YW8R7",
        "outputId": "4fa16707-9912-4dba-e7c7-7d80d6c6424e"
      },
      "source": [
        "#how many weekly observations betewenn first and last members\n",
        "#convert week to timestamp\n",
        "Emails.week = pd.to_datetime(Emails.week)\n",
        "\n",
        "maxdate = max(Emails[Emails.user == 998].week)\n",
        "mindate = min(Emails[Emails.user == 998].week)\n",
        "\n",
        "print((maxdate - mindate).days/7)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wnV8WF-qY7V8",
        "outputId": "31d5f6df-d916-405c-a6c0-b6c0b8bfba00"
      },
      "source": [
        "#how many weeks of data\n",
        "#notice we should have 26\n",
        "Emails[Emails.user == 998].shape"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(24, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qYQhQLvOZHqs"
      },
      "source": [
        "# Why 26 Rows?\n",
        "\n",
        "When doing time subtraction you should ask: should i add 1 to account for the offset at the end?\n",
        "\n",
        "Example\n",
        "\n",
        "I got info for 7, 14, 21 and 28\n",
        "How many points do I have in total?\n",
        "\n",
        "28-7 / 7 = 21/7 = 3\n",
        "\n",
        "But we obviously have 4 points, so we need to add 1 to account for the subtracted start date\n",
        "\n",
        "Then again, 28/7 = 4, why did was it subtracted in the first place?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bxRqgmxWxhHK",
        "outputId": "d47c4843-5152-49cf-b0c0-e78f1a76b460"
      },
      "source": [
        "#let's fill all missing weeks\n",
        "#multiindex - a cartesian product to create combinations of weeks and members\n",
        "complete_idx = pd.MultiIndex.from_product((set(Emails.week),set(Emails.user)))\n",
        "print(complete_idx)\n",
        "\n",
        "#using this new index, let's fill missing values with 0\n",
        "all_email = Emails.set_index(['week', 'user']).reindex(complete_idx, fill_value = 0).reset_index()\n",
        "#changing columns names so it matches what is being used in the book  I guess\n",
        "all_email.columns = ['week', 'member', 'EmailsOpened']\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MultiIndex([('2017-07-03',   1.0),\n",
            "            ('2017-07-03',   3.0),\n",
            "            ('2017-07-03',   5.0),\n",
            "            ('2017-07-03',   6.0),\n",
            "            ('2017-07-03',   9.0),\n",
            "            ('2017-07-03',  10.0),\n",
            "            ('2017-07-03',  14.0),\n",
            "            ('2017-07-03',  16.0),\n",
            "            ('2017-07-03',  20.0),\n",
            "            ('2017-07-03',  21.0),\n",
            "            ...\n",
            "            ('2018-02-19', 973.0),\n",
            "            ('2018-02-19', 977.0),\n",
            "            ('2018-02-19', 982.0),\n",
            "            ('2018-02-19', 984.0),\n",
            "            ('2018-02-19', 987.0),\n",
            "            ('2018-02-19', 991.0),\n",
            "            ('2018-02-19', 992.0),\n",
            "            ('2018-02-19', 993.0),\n",
            "            ('2018-02-19', 995.0),\n",
            "            ('2018-02-19', 998.0)],\n",
            "           length=93247)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "jf74oSHfylk6",
        "outputId": "2369681a-7cf4-4057-9fa1-728c0bb435c5"
      },
      "source": [
        "all_email[all_email.member == 998].sort_values('week')\n",
        "#we can see the empty weeks since the first register "
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>week</th>\n",
              "      <th>member</th>\n",
              "      <th>EmailsOpened</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>44736</th>\n",
              "      <td>2015-02-09</td>\n",
              "      <td>998.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>81388</th>\n",
              "      <td>2015-02-16</td>\n",
              "      <td>998.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>80849</th>\n",
              "      <td>2015-02-23</td>\n",
              "      <td>998.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87317</th>\n",
              "      <td>2015-03-02</td>\n",
              "      <td>998.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26949</th>\n",
              "      <td>2015-03-09</td>\n",
              "      <td>998.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39885</th>\n",
              "      <td>2018-04-30</td>\n",
              "      <td>998.0</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50126</th>\n",
              "      <td>2018-05-07</td>\n",
              "      <td>998.0</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12396</th>\n",
              "      <td>2018-05-14</td>\n",
              "      <td>998.0</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77076</th>\n",
              "      <td>2018-05-21</td>\n",
              "      <td>998.0</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76537</th>\n",
              "      <td>2018-05-28</td>\n",
              "      <td>998.0</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>173 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            week  member  EmailsOpened\n",
              "44736 2015-02-09   998.0           0.0\n",
              "81388 2015-02-16   998.0           0.0\n",
              "80849 2015-02-23   998.0           0.0\n",
              "87317 2015-03-02   998.0           0.0\n",
              "26949 2015-03-09   998.0           0.0\n",
              "...          ...     ...           ...\n",
              "39885 2018-04-30   998.0           3.0\n",
              "50126 2018-05-07   998.0           3.0\n",
              "12396 2018-05-14   998.0           3.0\n",
              "77076 2018-05-21   998.0           3.0\n",
              "76537 2018-05-28   998.0           3.0\n",
              "\n",
              "[173 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g4hcoEvhy1xb",
        "outputId": "525869ac-ba56-4d7c-fb27-5aaf6ddba4a6"
      },
      "source": [
        "#the zeroes at the start would mean when the member joined the organization\n",
        "#the zeros at the end would mean when he left the organization\n",
        "#let's trim it\n",
        "cutoff_dates = Emails.groupby('user').week.agg(['min', 'max']).reset_index()\n",
        "print(cutoff_dates.head())\n",
        "cutoff_dates = cutoff_dates.reset_index()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   user        min        max\n",
            "0   1.0 2015-06-29 2018-05-28\n",
            "1   3.0 2018-03-05 2018-04-23\n",
            "2   5.0 2017-06-05 2018-05-28\n",
            "3   6.0 2016-12-05 2018-05-28\n",
            "4   9.0 2016-07-18 2018-05-28\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tA4tTd4BzVOp"
      },
      "source": [
        "#this piece of code will generate a bunch of usererrors \n",
        "#for more infor https://stackoverflow.com/questions/41710789/boolean-series-key-will-be-reindexed-to-match-dataframe-index\n",
        "#choose NOT to fix it to use the book's code\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=UserWarning)\n",
        "\n",
        "#dropping the zeroes\n",
        "for _, row in cutoff_dates.iterrows():\n",
        "  member = row['user']\n",
        "  start_date = row['min']\n",
        "  end_date = row['max']\n",
        "  \n",
        "  all_email.drop(\n",
        "      all_email[all_email.member == member][all_email.week < start_date].index, \n",
        "      inplace=True)\n",
        "  \n",
        "  all_email.drop(\n",
        "      all_email[all_email.member == member][all_email.week > end_date].index, \n",
        "      inplace=True)\n",
        "\n",
        "#enables userwarning\n",
        "warnings.simplefilter(action='error', category=UserWarning)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pCKQ-nKy07tk",
        "outputId": "4b1b34b6-8884-431e-843b-18848f01dc2e"
      },
      "source": [
        "#the initial zeroes @ 2015 are gone\n",
        "print(all_email[all_email.member == 998].sort_values('week').head(10))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "            week  member  EmailsOpened\n",
            "49587 2017-12-04   998.0           1.0\n",
            "77615 2017-12-11   998.0           3.0\n",
            "29644 2017-12-18   998.0           3.0\n",
            "85161 2017-12-25   998.0           0.0\n",
            "1616  2018-01-01   998.0           3.0\n",
            "40963 2018-01-08   998.0           3.0\n",
            "87856 2018-01-15   998.0           2.0\n",
            "4850  2018-01-22   998.0           3.0\n",
            "53899 2018-01-29   998.0           2.0\n",
            "40424 2018-02-05   998.0           3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVfmLLId1GdR"
      },
      "source": [
        "#like we did with Emails, convert the date that is a string into timestamp\n",
        "#don't run this twice, the timestamp column is gone after set index\n",
        "Donations.timestamp = pd.to_datetime(Donations.timestamp)\n",
        "Donations.set_index('timestamp', inplace = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MsaxJgRl3ibw",
        "outputId": "4bacf5da-64dd-4365-f4f8-863fbc7fe984"
      },
      "source": [
        "#https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.apply.html\n",
        "#functional programming apply anon function / https://en.wikipedia.org/wiki/Apply\n",
        "\n",
        "#resample is a pandas function @ https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.resample.html#pandas.Series.resample\n",
        "#notice that we apply the resample to the .amount series\n",
        "#the \"W-MON\" is the rule, more information @ https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#resampling\n",
        "agg_don = Donations.groupby('user').apply(\n",
        "  lambda df: df.amount.resample(\"W-MON\").sum().dropna()\n",
        ")\n",
        "\n",
        "#results look weird tho\n",
        "print(agg_don.head(15))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "user  timestamp \n",
            "0.0   2015-03-30    25.0\n",
            "      2015-04-06     0.0\n",
            "      2015-04-13     0.0\n",
            "      2015-04-20     0.0\n",
            "      2015-04-27     0.0\n",
            "      2015-05-04     0.0\n",
            "      2015-05-11     0.0\n",
            "      2015-05-18     0.0\n",
            "      2015-05-25     0.0\n",
            "      2015-06-01     0.0\n",
            "      2015-06-08     0.0\n",
            "      2015-06-15     0.0\n",
            "      2015-06-22     0.0\n",
            "      2015-06-29     0.0\n",
            "      2015-07-06     0.0\n",
            "Name: amount, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 799
        },
        "id": "XXOZ6lbU3334",
        "outputId": "a445d3b4-26e1-4d60-ae56-348778f97876"
      },
      "source": [
        "#we should be able to join the agg_don to the all_emails things\n",
        "merged_df = pd.DataFrame()\n",
        "for member, member_email in all_email.groupby('member'):\n",
        "  #fix?\n",
        "  member_donations = agg_don[member]\n",
        "  #it's already timestamp\n",
        "  #member_donations.set_index('timestamp', inplace=True)\n",
        "  member_email.set_index('week', inplace=True)\n",
        "  member_email = all_email[all_email.member == member]\n",
        "  member_email.sort_values('week').set_index('week')\n",
        "\n",
        "  df = pd.merge(\n",
        "      member_email, \n",
        "      member_donations, \n",
        "      how = 'left', \n",
        "      left_index = True, \n",
        "      right_index = True)\n",
        "  \n",
        "  df.fillna(0)\n",
        "\n",
        "  #why member_x and not member?\n",
        "  df['member'] = member\n",
        "  print(df)\n",
        "  merged_df = merged_df.append(df)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "            week  member  EmailsOpened  amount\n",
            "0     2017-07-03     1.0           3.0     NaN\n",
            "539   2017-06-26     1.0           3.0     NaN\n",
            "1078  2018-01-01     1.0           3.0     NaN\n",
            "1617  2015-08-03     1.0           1.0     NaN\n",
            "2156  2017-05-01     1.0           3.0     NaN\n",
            "...          ...     ...           ...     ...\n",
            "90552 2017-10-09     1.0           3.0     NaN\n",
            "91091 2016-03-14     1.0           3.0     NaN\n",
            "91630 2017-10-30     1.0           3.0     NaN\n",
            "92169 2015-07-13     1.0           2.0     NaN\n",
            "92708 2018-02-19     1.0           3.0     NaN\n",
            "\n",
            "[153 rows x 4 columns]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2897\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2898\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2899\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Float64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Float64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 3.0",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-49-29fd4b4efae0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmember\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmember_email\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_email\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'member'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0;31m#fix?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m   \u001b[0mmember_donations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magg_don\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmember\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m   \u001b[0;31m#it's already timestamp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0;31m#member_donations.set_index('timestamp', inplace=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    880\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mkey_is_scalar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 882\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_hashable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m    988\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m         \u001b[0;31m# Similar to Index.get_value, but we do not fall back to positional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m         \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_values_for_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/multi.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method)\u001b[0m\n\u001b[1;32m   2702\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2703\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2704\u001b[0;31m             \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_level_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2705\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_maybe_to_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/multi.py\u001b[0m in \u001b[0;36m_get_level_indexer\u001b[0;34m(self, key, level, indexer)\u001b[0m\n\u001b[1;32m   2967\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2968\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2969\u001b[0;31m             \u001b[0mcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_loc_single_level_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlevel_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2970\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2971\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlevel\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlexsort_depth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/multi.py\u001b[0m in \u001b[0;36m_get_loc_single_level_index\u001b[0;34m(self, level_index, key)\u001b[0m\n\u001b[1;32m   2635\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2636\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2637\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mlevel_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2639\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/numeric.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m    422\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mnan_idxs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mcache_readonly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2898\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2899\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2900\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2902\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 3.0"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S1Mb27dDx1TP"
      },
      "source": [
        "RECAPING SOME TECHNIQUES\n",
        "from worked example pg 27-35\n",
        "\n",
        "1. recalibrate data resolution. data might come daily, but we only need weekly.\n",
        "\n",
        "2. avoid lookahead by NOT using data for timestamps that produces data availability???\n",
        "\n",
        "3. record all relevant time periods even if nothing happened. a zero count is as important as any other\n",
        "\n",
        "4. avoid lookahead by NOT using data for timestamps that produce information we shiouldn't know yet about\n",
        "\n",
        "Timestamps are specially tricky to work with due to their complexity. It is important to understand what a ts means. Is it when the event happened? Or was it when it was recorded into a table? Maybe it was when the user logged into the system? Or when the data migrated tables. If you can, reading the code that generated the data might help, even better would be talking to those who wrote the code, and in a perfect world, documentation that correctly reflects code. \n",
        "\n",
        "In most cases, we'll have to do some imperical research.\n",
        "\n",
        "Analyse a single user's tss and then expand to other users. Always consider that the ts might be the user's localtime, meaning, you can notice usage behavior to be directly correlated to choronology.\n",
        "\n",
        "You can also subtract the previous entry ts from the current and look for zeroes. Several entries on the same ts indicate a server behavior.\n",
        "\n",
        "Psychological Time Discounting / Psychological distance. People are more optimistic when estimating things in the distant future\n",
        "\n",
        "Cleaning data basics:\n",
        "\n",
        "-missing data\n",
        "\timputation, fill in missing data based on the whole database\n",
        "\titerpolation, use near points to predict missing values \n",
        "\tdeletion of affected time periods, ignore time periods we don't have data\n",
        "\n",
        "R data.table has a rolling join that seems to be amazing the joining on timestamps and a zoo package that has a bunch of timeseries related functions\n",
        "\n",
        "foward fill makes more sense even if fancier methods are possible, think about what the missing data could be\n",
        "\n",
        "take notice when using moving averages and using mean deviations when inerpolating because lookaheads\n",
        "\n",
        "-upsampling and downsampling\n",
        "\tselect output every nth element\n",
        "\tto focus on seasons, pick a single month every year, or a single day every week\n",
        "\tin irregular time series, rolling join\n",
        "\t\n",
        "-smoothing\n",
        "\twhy tho?\n",
        "\tdata preparation\n",
        "\tfeature generation\n",
        "\tprediction\n",
        "\tvisualization\n",
        "\t\n",
        "it's important to check outcomes affected by smoothing\n",
        "\n",
        "using exponential smoothing (and averages on this matter) gives more weight to recent data vs old data\n",
        ">check more resources on page 69\n",
        "\n",
        "pandas function ewma for exponential smoothing\n",
        "\n",
        "smoothing is so comon that you should use it as a easy null model when testing against fancier methods\n",
        "\n",
        "starting smoothing calculations may be problematic, if you think about two points, a exponential operation would consider the first point to be the sum of knowledge of what came before\n",
        "\n",
        ">Seasonal Data\n",
        "\n",
        "to see seasonal data, a different plot might help.\n",
        "\n",
        "pg62 shows a single line of R to decompose components: seasonal, trend, remainder\n",
        "\n",
        "documentation available at\n",
        "\n",
        "https://www.rdocumentation.org/packages/stats/versions/3.6.2/topics/stl\n",
        "\n",
        "TIMEZONES: everyone hates them\n",
        "pickling timezone objects is problematic \n",
        "why? bloggers mentioned it\n",
        "\n",
        "PREVENTING LOOKAHEAD\n",
        "\n",
        "-when smoothing data, experiment\n",
        "-build everything on small data and introduce random spot checks\n",
        "-for each kind of data, check what the timestamps relate to\n",
        "-use rolling testing or cross validation, RANDOMIZING TRAINING VERSUS TESTING DATA DOES NOT WORK WITH TIME SERIES\n",
        "-intentionally introduce lookahead, if you know a model's accuracy with lookahead, it's easier to set a maximum for the model ur building\n",
        "-add features slowly, any jump in acc should be explaned by lookahead\n",
        "\n",
        ">Review of functional data\n",
        "analysis / https://perma.cc/3DNT-J9EZ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33DocB8ewuY9"
      },
      "source": [
        ""
      ]
    }
  ]
}